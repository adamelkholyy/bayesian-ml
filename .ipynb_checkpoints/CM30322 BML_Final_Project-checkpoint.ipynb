{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CM30322 :: Final project\n",
    "\n",
    "**Total Marks 25 (25% of overall unit grade).** \n",
    "\n",
    "*Submission deadline: 8pm, May 03, 2024. Please submit this file along with your individual report in Moodle*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission & Marking\n",
    "\n",
    "This exercise is assessed, and the marks will contribute to your final grade. For this exercise there are a number of places where you are expected to enter your own code. Please see the BML Final Project Specification document for details. \n",
    "\n",
    "Every place you have to add code is described in the text and specifically indicated by the comment:\n",
    "\n",
    "`#### **** YOUR CODE HERE **** ####`\n",
    "\n",
    "\n",
    "The workbook you submit must be this `.ipynb` file, which is saved into the directory you're running Jupyter; alternatively you can download it from the menu above using `File -> Download As -> Notebook (.ipynb)`. Remember to save your work regularly (Save and Checkpoint in the File menu, the icon of a floppy disk, or Ctrl-S); the version you submit should have all code blocks showing the results (if any) of execution below them.\n",
    "\n",
    "**You should take care to avoid any suggestion of plagiarism in your submission.** There is helpful information on how to avoid plagiarism on the University website: http://www.bath.ac.uk/library/help/infoguides/plagiarism.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project setup\n",
    "\n",
    "This coursework involves the evaluation of Bayesian modelling methods on a real multivariate regression task. Please check the pdf file for the details of the project.\n",
    "\n",
    "- <font color=Red> Please try to use fixed random seeds to make your results reproducible </font>\n",
    "\n",
    "- <font color=Red> Please do NOT change the name of the fixed variables, as Task 2 - Task 5 of this coding exercises are auto-marked </font>\n",
    "\n",
    "The marks for Task 1 will be awarded based only on the content of the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T16:04:14.843249Z",
     "start_time": "2022-04-06T16:04:13.852342Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import hmc_Lab as hmc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 : Exploratory analysis (Section 4.1 in the specification doc)\n",
    "\n",
    "\n",
    "Undertake an initial exploratory analysis of the training data and summarise. Code in Task 1 will NOT by auto-marked. Results of Task 1 will be assessed along with your individual report, i.e., 4 marks in total. \n",
    "\n",
    " - <font color=Red> Please perserve the variables `X_train` and  `y_train` representing the normalised data in numpy array, as required for the following exercises  </font>\n",
    "\n",
    " - `X_train` is an np.array with shape (384, 9). The 1st column is a constant (bias) $x_0$ and the 2nd to the 9th columns are data variables $x_1,x_2,\\dots,x_8$\n",
    "\n",
    " - `y_train` is also an np.array with shape (384,), representing the target variable $y$ \n",
    " \n",
    " -  Please utilize zero-mean normalization on `X_train`and <font color=Red>refrain</font> from applying any normalization technique to obtain `y_train`.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T16:04:14.847098Z",
     "start_time": "2022-04-06T16:04:14.845333Z"
    }
   },
   "outputs": [],
   "source": [
    "#### **** YOUR CODE HERE **** ####  \n",
    "\n",
    "#### **** You can add extra cells to illustrate your results **** ####  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T16:45:00.563857Z",
     "start_time": "2023-03-25T16:45:00.561764Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check whether fixed variables are correctly defined ..\n",
    "try:\n",
    "    if not isinstance(X_train,np.ndarray):\n",
    "        print('X_train should be an array')        \n",
    "    if X_train.shape != (384,9):\n",
    "        print('X_train is arranged in wrong shape')\n",
    "except Exception as err:\n",
    "    print('Error output:', err)\n",
    "    \n",
    "try:\n",
    "    if not isinstance(y_train,np.ndarray):\n",
    "        print('y_train should be an array')        \n",
    "    if y_train.shape != (384,):\n",
    "        print('y_train is arranged in wrong shape')\n",
    "    if y_train.mean()<10:\n",
    "        print('Do not apply any normalization technique to obtain `y_train`')\n",
    "except Exception as err:\n",
    "    print('Error output:', err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Task 2 : Type-2 maximum likelihood (Section 4.2 in the specification doc)\n",
    "\n",
    "###  **(9 marks for coding part)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisions are defined as: $\\alpha = 1 / \\sigma_w^2$ and $ \\beta = 1 / \\sigma_{\\epsilon}^2 $\n",
    "\n",
    "Assume priors of $\\alpha$ and $\\beta$ follow flat Uniform distributions, please derive a likelihood function $(y|\\alpha, \\beta)$ (`compute_log_marginal`) to compute the *log-ikelihood* for the Bayesian linear regression problem using $X$ and hyperparameters $\\alpha$ and $\\beta$. \n",
    "\n",
    "In Lecture 4, we have illustrated the equations of finding the most probable hyperparameters to maximise the likelihood with respect to the hyperparameters.\n",
    "\n",
    "\n",
    "`X`: this is an np.array equivalent to matrix $X$ in the specification doc, e.g., `X_train`, `X_test`.\n",
    "\n",
    "`y`: this is an np.array equivalent totarget $y$ in the specification doc, e.g., `y_train`, `y_test`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T16:04:14.860310Z",
     "start_time": "2022-04-06T16:04:14.857912Z"
    }
   },
   "outputs": [],
   "source": [
    "## Compute log-likelihood\n",
    "\n",
    "def compute_log_marginal(X, y, alph, beta):\n",
    "    #### **** YOUR CODE HERE **** ####   \n",
    "\n",
    "    return lgp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute log-evidence (marginal likelihood) `log_prob_y` and plot the 'contourf' of the log-posterior distribution.\n",
    "\n",
    "- The x-axis should be the value of $log \\alpha$ and y-axis the $log\\beta$, `log_prob_y` represents the log-evidence. For each axis, it is recommended to use \n",
    "`np.linspace(-5,0,100)`\n",
    "\n",
    "- It is strongly recommended that you use only natural logarithms for hyper-parameter scales. That is, you would use `numpy.exp()` and `numpy.log()` functions to convert (or to convert back) the logarithm terms, <font color=Red> which is different from the previous coursework Part2</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T16:04:14.865483Z",
     "start_time": "2022-04-06T16:04:14.862299Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### **** YOUR CODE HERE **** ####   \n",
    "\n",
    "\n",
    "# Check whether your variables are correctly defined ..\n",
    "try:\n",
    "    if not isinstance(log_prob_y,np.ndarray):\n",
    "        print('log_prob_y should be an array')        \n",
    "    if log_prob_y.shape != (100,100):\n",
    "        print('log_prob_y is arranged in a wrong shape')\n",
    "except Exception as err:\n",
    "    print('Error output:', err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the most proboble values of the parameters $\\alpha$ and $\\beta$ and the corresponding log-likelihood value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T16:04:14.869511Z",
     "start_time": "2022-04-06T16:04:14.867274Z"
    }
   },
   "outputs": [],
   "source": [
    "#### **** YOUR CODE HERE **** ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation using `plt.contourf`for the posterior distribution and indicate the most probable value (with a highlighted marker) in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T16:04:14.907653Z",
     "start_time": "2022-04-06T16:04:14.871562Z"
    }
   },
   "outputs": [],
   "source": [
    "#### **** YOUR CODE HERE **** ####   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `compute_posterior(X, y, alph, beta)`  to compute the posterior mean $\\mathbf{\\mu}$ (`Mu`) and covariance $\\mathbf{\\Sigma}$ (`SIGMA`) for the Bayesian linear regression model, and return `Mu` and `SIGMA` for the posterior in the np.array format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T16:04:14.913930Z",
     "start_time": "2022-04-06T16:04:14.911445Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_posterior(X, y, alph, beta):\n",
    "    #### **** YOUR CODE HERE **** ####\n",
    "\n",
    "    return Mu, SIGMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the predicted weights and print out the corresponding RMSE for training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T16:04:14.918700Z",
     "start_time": "2022-04-06T16:04:14.916908Z"
    }
   },
   "outputs": [],
   "source": [
    "#### **** YOUR CODE HERE **** ####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Verify HMC on a standard 2D Gaussian example (Section 4.3 in the specification doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **(7 marks for coding part)**\n",
    "\n",
    "## The \"Distribution\"\n",
    "\n",
    "Complete the following functions:\n",
    "\n",
    "- `energy_func(x)`: the energy function, return negative log pdf value in float format\n",
    "- `energy_grad(x)`: the gradient function returns a numpy array containing the partial derivatives of the energy function with respect to the parameters/hyper-parameters.\n",
    "- `covar`: Covariance matrix for 2-dimensional gaussian. It is an numpy array with shape (2,2), e.g,  np.array([[1.0875,1],[1,1.0875]]) \n",
    "\n",
    "- `R`: the number of samples desired\n",
    "- `L`: number of simulation steps; for this simple case, 20 is easily enough\n",
    "- `eps`: simulation step length; set by trial-and-error to give approx. 90% acceptance\n",
    "- `burn`: simply set to `R/10`\n",
    "- `checkgrad`: set to true to test the consistency of `energy_func` and `energy_grad`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T16:04:14.943668Z",
     "start_time": "2022-04-06T16:04:14.941113Z"
    }
   },
   "outputs": [],
   "source": [
    "def energy_func(x, covar):\n",
    "    #### **** YOUR CODE HERE **** ####\n",
    "    \n",
    "    return neglgp\n",
    "\n",
    "def energy_grad(x, covar):\n",
    "    #### **** YOUR CODE HERE **** ####\n",
    "    \n",
    "    \n",
    "    return g\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the Distribution\n",
    "Before we run the sampler, let's visualise the distribution over an appropriate\n",
    "grid of values. Please specify `covar` to plot figures, an naive example of `covar` has been shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T16:04:15.132283Z",
     "start_time": "2022-04-06T16:04:14.945961Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#### **** YOUR CODE BELOW **** ####\n",
    "\n",
    "covar = np.array([[1,0.9],[0.9,1]]) \n",
    "\n",
    "#### **** YOUR CODE ABOVE **** ####\n",
    "\n",
    "f = 5  # The \"frequency\" argument for the energy, used here to demonstrate how to use \"args\"\n",
    "# Other plotting parameters\n",
    "fsz = (10,8)\n",
    "gsz = 100\n",
    "lim = 3\n",
    "\n",
    "# Setup the mesh grid\n",
    "\n",
    "gx = np.linspace(-lim, lim, gsz)\n",
    "GX, GY = np.meshgrid(gx, gx)\n",
    "Gsz = GX.size\n",
    "G = np.hstack((GX.reshape((Gsz, 1)), GY.reshape((Gsz, 1))))\n",
    "\n",
    "# Plot the figure\n",
    "plt.figure(figsize=fsz)\n",
    "P = np.asarray([np.exp(-energy_func(g, covar)) for g in G])\n",
    "plt.contour(GX, GY, P.reshape((gsz, gsz)), cmap='Reds', linewidths=3, zorder=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T16:04:43.415213Z",
     "start_time": "2022-04-06T16:04:43.412702Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    if not isinstance(covar ,np.ndarray):\n",
    "        print('covar  should be an array')        \n",
    "    if covar .shape != (2,2):\n",
    "        print('covar  is arranged in wrong shape')\n",
    "except Exception as err:\n",
    "    print('Error output:', err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T16:04:44.387058Z",
     "start_time": "2022-04-06T16:04:44.376115Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialise the state for the first time step\n",
    "x0 = np.random.normal(size=2)\n",
    "\n",
    "# Call the function from the pre-defined hmc module\n",
    "hmc.gradient_check(x0, energy_func, energy_grad, covar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters\n",
    "\n",
    "Please tune optimal hyper-parameters incluidng `R`, `L`, and `eps` in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T16:04:46.883980Z",
     "start_time": "2022-04-06T16:04:46.876236Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed=1)  # Fix the random seed for better reproducibility\n",
    "\n",
    "#### **** YOUR CODE BELOW **** ####\n",
    "\n",
    "\n",
    "# R=\n",
    "# L = \n",
    "# eps = \n",
    "# burn = \n",
    "\n",
    "#### **** YOUR CODE ABOVE **** ####\n",
    "\n",
    "# HMC sampling\n",
    "S, *_ = hmc.sample(x0, energy_func, energy_grad, R, L, eps, burn=burn, checkgrad=True, args=[covar])\n",
    "# Plot the figure\n",
    "plt.figure(figsize=fsz)\n",
    "plt.plot(S[:, 0], S[:, 1], '.', ms=6, color='CadetBlue', alpha=0.25, zorder=0)\n",
    "plt.contour(GX, GY, P.reshape((gsz, gsz)), cmap='Reds', linewidths=3, zorder=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T16:04:15.143577Z",
     "start_time": "2022-04-06T16:04:13.873Z"
    }
   },
   "outputs": [],
   "source": [
    "#### **** YOUR CODE HERE **** ####\n",
    "\n",
    "#### **** You can add extra figures to support the individual report **** ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Apply HMC to the Linear Regression Model (Section 4.4 in the specification doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **(9 marks for coding part)**\n",
    "\n",
    "Complete the functions and the HMC code for this task:\n",
    "\n",
    "- `energy_func_lr(hps, x, y)`: where `hps` is a 2+9 dimension array, where the 1st dimension represents $\\alpha$, and the 2nd represnets $\\beta$. Thus, `hps[0]` should be the current $\\alpha$, `hps[1]` the $\\beta$ and `hps[2:]` represent the weights `w` for constant and 8 variables respectively. `x` and `y` is the x and y array of training data.\n",
    "\n",
    "- `energy_grad_lr(hps, x, y)`: the gradient function returns an array containing the partial derivatives of the energy function. should be the same shape for hps. \n",
    "\n",
    "- `R`: the number of samples desired\n",
    "- `L`: number of simulation steps; for this simple case, 20 is easily enough\n",
    "- `eps`: simulation step length; set by trial-and-error to give approx. 90% acceptance\n",
    "- `burn`: simply set to `R/10`\n",
    "- `checkgrad`: set to true to test the consistency of `energy_func` and `energy_grad`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T16:04:15.144865Z",
     "start_time": "2022-04-06T16:04:13.874Z"
    }
   },
   "outputs": [],
   "source": [
    "def energy_func_lr(hps, x, y):\n",
    "    #### **** YOUR CODE HERE **** ####\n",
    "    \n",
    "    return neglgp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T16:04:15.146105Z",
     "start_time": "2022-04-06T16:04:13.875Z"
    }
   },
   "outputs": [],
   "source": [
    "def energy_grad_lr(hps, x, y):\n",
    "    \n",
    "    #### **** YOUR CODE HERE **** ####\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T16:04:15.147415Z",
     "start_time": "2022-04-06T16:04:13.877Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed=1) \n",
    "\n",
    "#### **** YOUR CODE HERE **** ####\n",
    "\n",
    "\n",
    "\n",
    "#### you can adjust the hpyer-parameters. \n",
    "\n",
    "\n",
    "S, *_ = hmc.sample(x0, energy_func_lr, energy_grad_lr, R, L, eps, burn=burn, checkgrad=True, args=[X_train, Y_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out the RMSE and plot figures for your report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T16:04:15.148669Z",
     "start_time": "2022-04-06T16:04:13.878Z"
    }
   },
   "outputs": [],
   "source": [
    "#### **** YOUR CODE HERE **** ####\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
